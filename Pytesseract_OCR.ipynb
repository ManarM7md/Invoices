{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79nZMdUgizho",
        "outputId": "a5bd703d-1d00-4e3c-f8b8-6b2748ca11f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-ara is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langdetect easyocr pytesseract\n",
        "!sudo apt -q install tesseract-ocr tesseract-ocr-ara\n",
        "!pip -q install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from pytesseract import pytesseract\n",
        "import easyocr\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Defining paths to tesseract.exe\n",
        "pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "\n",
        "class ExtractTextOCR:\n",
        "    def __init__(self):\n",
        "        # config settings\n",
        "        self.config=r'--oem 3 --psm 6'\n",
        "\n",
        "        # Language dictionaries for pytesseract and easyocr\n",
        "        self.languages = {\n",
        "            'english': ('eng', 'en'),\n",
        "            'french': ('fra', 'fr'),\n",
        "            'spanish': ('spa', 'es'),\n",
        "            'arabic': ('ara', 'ar'),\n",
        "            'german': ('deu', 'de'),\n",
        "            'italian': ('ita', 'it'),\n",
        "        }\n",
        "\n",
        "    def prepare(self, image, show=False):\n",
        "        \"\"\" Preprocess the image to improve OCR accuracy \"\"\"\n",
        "        # Read the image in grayscale\n",
        "        img = None\n",
        "\n",
        "        # Handle if image is a file path\n",
        "        if isinstance(image, str):\n",
        "            img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Handle if image is an OpenCV matrix (np.ndarray)\n",
        "        elif isinstance(image, np.ndarray):\n",
        "            img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Handle if image is a PIL image\n",
        "        elif isinstance(image, Image.Image):\n",
        "            img = np.array(image.convert('L'))  # Convert to grayscale using PIL\n",
        "\n",
        "        # If the image is not provided or invalid, raise an error\n",
        "        if img is None:\n",
        "            raise ValueError(\"Invalid image input. Please provide an image file path, OpenCV image matrix, or PIL image.\")\n",
        "\n",
        "        # # Apply image preprocessing techniques (Bad Choice)\n",
        "        img = cv2.resize(img, (1440, 2560), interpolation=cv2.INTER_AREA)\n",
        "        enhancer = ImageEnhance.Sharpness(Image.fromarray(img))\n",
        "        img = np.array(enhancer.enhance(1.5))  # Increase sharpness\n",
        "\n",
        "        # Show the enhanced image\n",
        "        if show:\n",
        "            # cv2.imwrite(\"enhanced_image.jpg\", img)\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            plt.title('Enhanced Image')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        return img\n",
        "\n",
        "    def run(self, image_path, language, tesseract=True, show_img=False, verbose=0):\n",
        "        # Set the languages based on the user input\n",
        "        if language.lower() in self.languages:\n",
        "            tesseract_lang, easyocr_lang = self.languages[language.lower()]\n",
        "        else:\n",
        "            raise ValueError(f\"Language '{language}' is not supported. Please choose from {list(self.languages)}.\")\n",
        "\n",
        "        # Preprocess the image\n",
        "        preprocessed_image = self.prepare(image_path, show=show_img)\n",
        "        if tesseract:\n",
        "            text = pytesseract.image_to_string(preprocessed_image, lang=f'eng+{tesseract_lang}', config=self.config)\n",
        "        else:\n",
        "            reader = easyocr.Reader(['en', easyocr_lang], gpu=True)\n",
        "            text = \" \".join(reader.readtext(preprocessed_image, detail=0, paragraph=True))\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Extracted Text ({'tesseract' if tesseract else 'easyocr'}):\", text)\n",
        "        return text\n",
        "\n",
        "    def test(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "iDK-pYrLi99q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    text_model = ExtractTextOCR()\n",
        "    language = 'arabic'\n",
        "    text = text_model.run(r\"/content/img.png\",language=language, tesseract=True)\n",
        "    print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcl25OqtjGEa",
        "outputId": "639d3b03-45b3-435f-d6a8-e4f4c11da91c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#1024\n",
            "\n",
            "BILLED TO: Really Great Company\n",
            "PAY TO: Avery Davis\n",
            "\n",
            "123 Anywhere St., Any City\n",
            "\n",
            "123-456-7890\n",
            "Bank Really Great Bank\n",
            "Account Name John Smith\n",
            "BSB 000-000\n",
            "\\ccount Number OOOO OOOO\n",
            "DESCRIPTION RATE HOURS AMOUNT\n",
            "Content Plan S50, hr | $200.00\n",
            "Copy Writing $50/hr 2 S1O0.00\n",
            "Website Design 850) hr 5 $250.00\n",
            "Website Development $100/ht 3 $300,00\n",
            "SEO $50, hr | $200.00\n",
            "Sub-Total $1,250.00\n",
            "Package Discount (30%) $375.00\n",
            "TOTAL $875.00\n",
            "Payment is required within 4 business days of invoice date, Please send\n",
            "remittance to hello@reallygreatsite.com\n",
            "Thank vou for your business.\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.schema import StrOutputParser, AIMessage\n",
        "\n",
        "google_api_key = userdata.get(\"GOOGLE_API_KEY_1\")\n",
        "\n",
        "# Define the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['input'],\n",
        "    template=\"\"\"\n",
        "    You are an assistant. Your task is to take {input} and extract Description, RATE, HOURES, and Amount then put this in csv format.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "parameters ={'temperature': 0}\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                                  generation_config=parameters, api_key=google_api_key)\n",
        "\n",
        "\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "\n",
        "response = chain.invoke({'input': text})"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "U4gnf00OoFP9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "data = response\n",
        "lines = data.strip().split('\\n')\n",
        "data_rows = [line.split(',') for line in lines]\n",
        "\n",
        "# Saving the data into a CSV file\n",
        "csv_file_path = 'output_data.csv'\n",
        "with open(csv_file_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(data_rows)\n",
        "\n",
        "print(f\"Data saved to {csv_file_path} successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxPp_Io0nGRv",
        "outputId": "fd88aada-8c51-4508-e215-220fa25c1d93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to output_data.csv successfully.\n"
          ]
        }
      ]
    }
  ]
}